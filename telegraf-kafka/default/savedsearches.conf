# savedsearches.conf

#   ____             __ _                       _   _
#  / ___|___  _ __  / _(_) __ _ _   _ _ __ __ _| |_(_) ___  _ __
# | |   / _ \| '_ \| |_| |/ _` | | | | '__/ _` | __| |/ _ \| '_ \
# | |__| (_) | | | |  _| | (_| | |_| | | | (_| | |_| | (_) | | | |
#  \____\___/|_| |_|_| |_|\__, |\__,_|_|  \__,_|\__|_|\___/|_| |_|
#                         |___/
#

# The following search will initialize the default state of the component in the KVstore based collection
# The search is not intended to be run in normal circumstances, and will run automatically when we detect that the configuration is empty
[telegraf-kafka-configuration-init]
search = | makeresults | eval label="Zookeeper", state="enabled"\
| append [ | makeresults | eval label="Kafka_Broker", state="enabled" ]\
| append [ | makeresults | eval label="Kafka_Connect", state="enabled" ]\
| append [ | makeresults | eval label="Kafka_Burrow", state="enabled" ]\
| append [ | makeresults | eval label="Confluent_Kafka_Rest", state="enabled" ]\
| append [ | makeresults | eval label="Confluent_ksql_server", state="enabled" ]\
| append [ | makeresults | eval label="Confluent_Schema_Registry", state="enabled" ]\
| fields - _time\
| outputlookup telegraf_kafka_configuration
is_visible = false

[telegraf-kafka-configuration-init-disable]
search = | makeresults | eval label="Zookeeper", state="disable"\
| append [ | makeresults | eval label="Kafka_Broker", state="disable" ]\
| append [ | makeresults | eval label="Kafka_Connect", state="disable" ]\
| append [ | makeresults | eval label="Kafka_Burrow", state="disable" ]\
| append [ | makeresults | eval label="Confluent_Kafka_Rest", state="disable" ]\
| append [ | makeresults | eval label="Confluent_ksql_server", state="disable" ]\
| append [ | makeresults | eval label="Confluent_Schema_Registry", state="disable" ]\
| fields - _time\
| outputlookup telegraf_kafka_configuration
is_visible = false

#  _____           _
# |__  /___   ___ | | _____  ___ _ __   ___ _ __
#   / // _ \ / _ \| |/ / _ \/ _ \ '_ \ / _ \ '__|
#  / /| (_) | (_) |   <  __/  __/ |_) |  __/ |
# /____\___/ \___/|_|\_\___|\___| .__/ \___|_|
#                               |_|

# The following search will discover all zookeeper servers reporting to the telegraf metric indexes
[telegraf-kafka-zookeeper-servers]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="zookeeper.avg_latency" OR metric_name="zookeeper.open_file_descriptor_count" by env, label, server\
| fields env, label, server\
| eval role="zookeeper"\
| fields role, env, label, server

#  _  __      __ _           _               _
# | |/ /__ _ / _| | ____ _  | |__  _ __ ___ | | _____ _ __ ___
# | ' // _` | |_| |/ / _` | | '_ \| '__/ _ \| |/ / _ \ '__/ __|
# | . \ (_| |  _|   < (_| | | |_) | | | (_) |   <  __/ |  \__ \
# |_|\_\__,_|_| |_|\_\__,_| |_.__/|_|  \___/|_|\_\___|_|  |___/
#

[telegraf-kafka-kafka-brokers]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_controller.ActiveControllerCount.Value" by env, label, jolokia_agent_url\
| eval role="kafka_broker"\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| fields role, env, label, jolokia_agent_url, kafka_broker

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#

[telegraf-kafka-kafka-connect-workers]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_connect.worker.connector-count" by env, label, jolokia_agent_url\
| eval role="kafka_connect"\
| rex field=jolokia_agent_url "//(?<kafka_connect>[^:]*)\:"\
| fields role, env, label, jolokia_agent_url, kafka_connect

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#
#  _            _
# | |_ __ _ ___| | _____
# | __/ _` / __| |/ / __|
# | || (_| \__ \   <\__ \
#  \__\__,_|___/_|\_\___/
#
#   ______                              ______  _       _   __
#  / / ___|  ___  _   _ _ __ ___ ___   / / ___|(_)_ __ | | _\ \
# | |\___ \ / _ \| | | | '__/ __/ _ \ / /\___ \| | '_ \| |/ /| |
# | | ___) | (_) | |_| | | | (_|  __// /  ___) | | | | |   < | |
# | ||____/ \___/ \__,_|_|  \___\___/_/  |____/|_|_| |_|_|\_\| |
#  \_\                                                      /_/
#

[telegraf-kafka-kafka-connect-tasks]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_connect.source-task.source-record-poll-total" OR metric_name="kafka_connect.sink-task.sink-record-read-total" connector=* by env, label, jolokia_agent_url, connector\
| rename jolokia_agent_url as kafka_task_nodes\
| eval role=case(match(metric_name, "sink-task"), "kafka_sink_task", match(metric_name, "source-task"), "kafka_source_task")\
| fields - metric_name\
| rename connector as kafka_task\
| nomv kafka_task_nodes | rex field=kafka_task_nodes mode=sed "s/ /|/g"\
| fields role, env, label, kafka_task, kafka_task_nodes

#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | |_ ___  _ __ (_) ___ ___
# | ' // _` | |_| |/ / _` | | __/ _ \| '_ \| |/ __/ __|
# | . \ (_| |  _|   < (_| | | || (_) | |_) | | (__\__ \
# |_|\_\__,_|_| |_|\_\__,_|  \__\___/| .__/|_|\___|___/
#                                    |_|

[telegraf-kafka-kafka-topics]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_topic.MessagesInPerSec.Count" OR metric_name="kafka_topic.BytesInPerSec.Count" by env, label, jolokia_agent_url, topic\
| eval role="kafka_topic"\
| rename topic as kafka_topic, jolokia_agent_url as kafka_topic_brokers\
| nomv kafka_topic_brokers | rex field=kafka_topic_brokers mode=sed "s/ /|/g"\
| fields role, env, label, kafka_topic, kafka_topic_brokers

#   ____             __ _                  _
#  / ___|___  _ __  / _| |_   _  ___ _ __ | |_
# | |   / _ \| '_ \| |_| | | | |/ _ \ '_ \| __|
# | |__| (_) | | | |  _| | |_| |  __/ | | | |_
#  \____\___/|_| |_|_| |_|\__,_|\___|_| |_|\__|
#
#  _  __      __ _           ____       _                                ____            _     _
# | |/ /__ _ / _| | ____ _  / ___|  ___| |__   ___ _ __ ___   __ _      |  _ \ ___  __ _(_)___| |_ _ __ _   _
# | ' // _` | |_| |/ / _` | \___ \ / __| '_ \ / _ \ '_ ` _ \ / _` |_____| |_) / _ \/ _` | / __| __| '__| | | |
# | . \ (_| |  _|   < (_| |  ___) | (__| | | |  __/ | | | | | (_| |_____|  _ <  __/ (_| | \__ \ |_| |  | |_| |
# |_|\_\__,_|_| |_|\_\__,_| |____/ \___|_| |_|\___|_| |_| |_|\__,_|     |_| \_\___|\__, |_|___/\__|_|   \__, |
#                                                                                  |___/                |___/

[telegraf-kafka-schema-registry]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_schema-registry.master-slave-role.master-slave-role" by env, label, jolokia_agent_url\
| eval role="schema-registry"\
| rex field=jolokia_agent_url "//(?<kafka_schema_registry>[^:]*)\:"\
| fields role, env, label, jolokia_agent_url, kafka_schema_registry

#   ____             __ _                  _
#  / ___|___  _ __  / _| |_   _  ___ _ __ | |_
# | |   / _ \| '_ \| |_| | | | |/ _ \ '_ \| __|
# | |__| (_) | | | |  _| | |_| |  __/ | | | |_
#  \____\___/|_| |_|_| |_|\__,_|\___|_| |_|\__|
#
#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | | _____  __ _| |      ___  ___ _ ____   _____ _ __
# | ' // _` | |_| |/ / _` | | |/ / __|/ _` | |_____/ __|/ _ \ '__\ \ / / _ \ '__|
# | . \ (_| |  _|   < (_| | |   <\__ \ (_| | |_____\__ \  __/ |   \ V /  __/ |
# |_|\_\__,_|_| |_|\_\__,_| |_|\_\___/\__, |_|     |___/\___|_|    \_/ \___|_|
#                                        |_|

[telegraf-kafka-ksql-server]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_ksql-server.*messages-consumed-per-sec" OR metric_name="kafka_ksql-server.*messages-produced-per-sec" by env, label, jolokia_agent_url\
| eval role="ksql-server"\
| rex field=jolokia_agent_url "//(?<kafka_ksql_server>[^:]*)\:"\
| fields role, env, label, jolokia_agent_url, kafka_ksql_server

#   ____             __ _                  _
#  / ___|___  _ __  / _| |_   _  ___ _ __ | |_
# | |   / _ \| '_ \| |_| | | | |/ _ \ '_ \| __|
# | |__| (_) | | | |  _| | |_| |  __/ | | | |_
#  \____\___/|_| |_|_| |_|\__,_|\___|_| |_|\__|
#
#  _          __ _                             _
# | | ____ _ / _| | ____ _       _ __ ___  ___| |_
# | |/ / _` | |_| |/ / _` |_____| '__/ _ \/ __| __|
# |   < (_| |  _|   < (_| |_____| | |  __/\__ \ |_
# |_|\_\__,_|_| |_|\_\__,_|     |_|  \___||___/\__|
#

[telegraf-kafka-kafka-rest]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_kafka-rest.jetty-metrics.connections-active" by env, label, jolokia_agent_url\
| eval role="kafka_rest"\
| rex field=jolokia_agent_url "//(?<kafka_rest>[^:]*)\:"\
| fields role, env, label, jolokia_agent_url, kafka_rest

#  _     _       _            _ _
# | |   (_)_ __ | | _____  __| (_)_ __
# | |   | | '_ \| |/ / _ \/ _` | | '_ \
# | |___| | | | |   <  __/ (_| | | | | |
# |_____|_|_| |_|_|\_\___|\__,_|_|_| |_|
#
#  _  __      __ _                                     _ _
# | |/ /__ _ / _| | ____ _       _ __ ___   ___  _ __ (_) |_ ___  _ __
# | ' // _` | |_| |/ / _` |_____| '_ ` _ \ / _ \| '_ \| | __/ _ \| '__|
# | . \ (_| |  _|   < (_| |_____| | | | | | (_) | | | | | || (_) | |
# |_|\_\__,_|_| |_|\_\__,_|     |_| |_| |_|\___/|_| |_|_|\__\___/|_|
#

[telegraf-kafka-kafka-monitor]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_kafka-monitor.produce-availability-avg" OR metric_name="kafka_kafka-monitor.consume-availability-avg" by env, label, jolokia_agent_url\
| eval role="kafka_linkedin_monitor"\
| fields role, env, label, jolokia_agent_url

#  ____
# | __ ) _   _ _ __ _ __ _____      __
# |  _ \| | | | '__| '__/ _ \ \ /\ / /
# | |_) | |_| | |  | | | (_) \ V  V /
# |____/ \__,_|_|  |_|  \___/ \_/\_/
#

[telegraf-kafka-burrow-group]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="burrow_partition.status_code" by env, label, cluster, group\
| eval role="burrow_group"\
| where group!=""\
| fields role, env, label, cluster, group

[telegraf-kafka-burrow-partition]
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="burrow_partition.status_code" by env, label, cluster, group, topic, partition\
| eval role="burrow_partition"\
| where group!=""\
| fields role, env, label, cluster, group, topic, partition

#     _    _     _
#    / \  | |   | |
#   / _ \ | |   | |
#  / ___ \| |___| |___
# /_/   \_\_____|_____|
#
#   ____ ___  __  __ ____   ___  _   _ _____ _   _ _____ ____
#  / ___/ _ \|  \/  |  _ \ / _ \| \ | | ____| \ | |_   _/ ___|
# | |  | | | | |\/| | |_) | | | |  \| |  _| |  \| | | | \___ \
# | |__| |_| | |  | |  __/| |_| | |\  | |___| |\  | | |  ___) |
#  \____\___/|_|  |_|_|    \___/|_| \_|_____|_| \_| |_| |____/
#
#  ___ _   ___     _______ _   _ _____ ___  ______   __
# |_ _| \ | \ \   / / ____| \ | |_   _/ _ \|  _ \ \ / /
#  | ||  \| |\ \ / /|  _| |  \| | | || | | | |_) \ V /
#  | || |\  | \ V / | |___| |\  | | || |_| |  _ < | |
# |___|_| \_|  \_/  |_____|_| \_| |_| \___/|_| \_\|_|
#

# This report fills, updates and maintain the inventory kvstore collections for Kafka infrastructure components which are:

# - kafka_infra_inventory for traditional monitoring in a dedicated bare metal or virtual machine environment
# - kafka_infra_nodes_inventory for monitoring in a container environment where what matters is the minimal number of containers participating in the service

# Due to be run on a regular basis (once per day by default), the report does the following:

# For kafka_infra_inventory:

# - detects new components and to be added to the collection
# - sets a default value for grace period and maintenance_state according to the per components default macros
# - retrieve current settings for any existing component
# - if a component of the collection did not report metrics during the last 24 hours, the monitoring_state will be changed to disabled_autoforced to avoid
# continuously alerting, assuming a component failure that was not fixed for 24 hours shall not be monitored actively
# - finally flush the kvstore content with the new version

# For kafka_infra_nodes_inventory:

# - recycles the result from the search to account the current number of nodes per type of component (role)
# - retrieves any existing settings from the kvstore collection
# - defines default values accordingly, if no minimal number of nodes has been specified, the current number of nodes will be used
# - finally flush the kvstore content with the new version

[Update Kafka Infrastructure components inventory]
cron_schedule = 0 0,4,8,12,16,20 * * *
description = This report fills, updates and maintain the inventory kvstore collection for Kafka infrastructure components
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | savedsearch telegraf-kafka-zookeeper-servers | `zookeeper_default_monitoring_state` | rename server as name | fields env, label, name, role, monitoring_state\
| append [ | savedsearch telegraf-kafka-kafka-brokers | rename jolokia_agent_url as name | `kafka_broker_default_monitoring_state` | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-connect-workers | rename jolokia_agent_url as name | `kafka_connect_default_monitoring_state` | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-schema-registry | rename jolokia_agent_url as name | `schema_registry_default_monitoring_state` | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-ksql-server | rename jolokia_agent_url as name | `ksql_server_default_monitoring_state` | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-rest | rename jolokia_agent_url as name | `kafka_rest_default_monitoring_state` | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-monitor | rename jolokia_agent_url as name | `kafka_monitor_default_monitoring_state` | fields env, label, name, role, monitoring_state ]\
| eval grace_period="300"\
| rename grace_period as default_grace_period, monitoring_state as default_monitoring_state\
| join type=outer env, label, name [ | inputlookup kafka_infra_inventory | rename grace_period as current_grace_period, monitoring_state as current_monitoring_state | eval key = _key ]\
| eval grace_period=if(isnotnull(current_grace_period), current_grace_period, default_grace_period), monitoring_state=if(isnotnull(current_monitoring_state), current_monitoring_state, default_monitoring_state)\
| fields key, env, label, name, role, grace_period, monitoring_state\
| eval _time=now()\
| append [ | inputlookup kafka_infra_inventory | eval lasttime=if(isnull(lasttime), now()-86400, lasttime) | rename lasttime as _time | eval key = _key ]\
| stats latest(*) as "*", max(_time) as _time by env, label, name\
| rename key as _key\
| fields _key, env, label, name, role, grace_period, monitoring_state, _time\
| eval detection_delta=now()-_time\
| eval monitoring_state=if(detection_delta>86400, "disabled_autoforced", monitoring_state)\
| rename _time as lasttime | fields - detection_delta\
| outputlookup kafka_infra_inventory\
| stats count(name) as current_nodes_number by env, label, role | `nodes_number_default_monitoring_state`\
| join type=outer env, label, role [ | inputlookup kafka_infra_nodes_inventory  | fields - current_nodes_number | rename monitoring_state as current_monitoring_state | eval key = _key ]\
| rename monitoring_state as default_monitoring_state\
| rename key as _key\
| eval monitoring_state=if(isnotnull(current_monitoring_state), current_monitoring_state, default_monitoring_state)\
| fields _key, env, label, role, current_nodes_number, monitoring_state\
| lookup kafka_infra_nodes_inventory env, label, role OUTPUT minimal_nodes_number\
| eval minimal_nodes_number=if(isnotnull(minimal_nodes_number) AND isnum(minimal_nodes_number), minimal_nodes_number, current_nodes_number)\
| outputlookup kafka_infra_nodes_inventory

#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | |_ ___  _ __ (_) ___ ___
# | ' // _` | |_| |/ / _` | | __/ _ \| '_ \| |/ __/ __|
# | . \ (_| |  _|   < (_| | | || (_) | |_) | | (__\__ \
# |_|\_\__,_|_| |_|\_\__,_|  \__\___/| .__/|_|\___|___/
#                                    |_|
#  ___                      _
# |_ _|_ ____   _____ _ __ | |_ ___  _ __ _   _
#  | || '_ \ \ / / _ \ '_ \| __/ _ \| '__| | | |
#  | || | | \ V /  __/ | | | || (_) | |  | |_| |
# |___|_| |_|\_/ \___|_| |_|\__\___/|_|   \__, |
#                                         |___/
#

[Update Kafka topics inventory]
cron_schedule = 5 0,4,8,12,16,20 * * *
description = This report updates the Kafka topics kvstore collection
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_topic.MessagesInPerSec.Count" OR metric_name="kafka_topic.BytesInPerSec.Count" topic!="__*" topic!="_*" by env, label, topic\
| fields - metric_name\
| eval grace_period="300"\
| `kafka_topics_default_monitoring_state`\
| lookup kafka_topics_monitoring env, label, topic OUTPUT topic as collection_found | where isnull(collection_found) | fields - collection_found\
| outputlookup kafka_topics_monitoring append=t key_field=_key

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#
#  _            _
# | |_ __ _ ___| | _____
# | __/ _` / __| |/ / __|
# | || (_| \__ \   <\__ \
#  \__\__,_|___/_|\_\___/
#
#  ___                      _
# |_ _|_ ____   _____ _ __ | |_ ___  _ __ _   _
#  | || '_ \ \ / / _ \ '_ \| __/ _ \| '__| | | |
#  | || | | \ V /  __/ | | | || (_) | |  | |_| |
# |___|_| |_|\_/ \___|_| |_|\__\___/|_|   \__, |
#                                         |___/
#

[Update Kafka Connect tasks inventory]
cron_schedule = 10 0,4,8,12,16,20 * * *
description = This scheduled report will update the Kafka Connect task inventory collection
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_connect.source-task.source-record-poll-total" OR metric_name="kafka_connect.sink-task.sink-record-read-total" connector=* by env, label connector\
| eval role=case(match(metric_name, "sink-task"), "kafka_sink_task", match(metric_name, "source-task"), "kafka_source_task")\
| eval grace_period="300"\
| `kafka_connect_tasks_default_monitoring_state`\
| fields env, label, connector, role, grace_period, monitoring_state\
| eval lasttime=now()\
| append\
[| inputlookup kafka_connect_tasks_monitoring\
| eval key = _key ]\
| stats max(lasttime) as lasttime, first(_key) as _key, first(*) as "*" by env, label, connector\
| outputlookup kafka_connect_tasks_monitoring append=t key_field=_key\
| lookup kafka_connect_tasks_monitoring env, label, connector, role OUTPUT connector as found | where isnull(found) | fields - found\
| outputlookup kafka_connect_tasks_monitoring append=t

#  ____
# | __ ) _   _ _ __ _ __ _____      __
# |  _ \| | | | '__| '__/ _ \ \ /\ / /
# | |_) | |_| | |  | | | (_) \ V  V /
# |____/ \__,_|_|  |_|  \___/ \_/\_/
#
#   ____
# / ___|___  _ __  ___ _   _ _ __ ___   ___ _ __ ___
# | |   / _ \| '_ \/ __| | | | '_ ` _ \ / _ \ '__/ __|
# | |__| (_) | | | \__ \ |_| | | | | | |  __/ |  \__ \
#  \____\___/|_| |_|___/\__,_|_| |_| |_|\___|_|  |___/
#
#  _                      _
# (_)_ ____   _____ _ __ | |_ ___  _ __ _   _
# | | '_ \ \ / / _ \ '_ \| __/ _ \| '__| | | |
# | | | | \ V /  __/ | | | || (_) | |  | |_| |
# |_|_| |_|\_/ \___|_| |_|\__\___/|_|   \__, |
#                                       |___/

[Update Kafka Burrow group consumers inventory]
cron_schedule = 15 0,4,8,12,16,20 * * *
description = This scheduled report will update the Kafka Burrow group consumers inventory collection
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="burrow_partition.status_code" by env, label, cluster, group\
| eval role="burrow_group"\
| where group!=""\
| fields role, env, label, cluster, group\
| `kafka_burrow_consumers_default_monitoring_state`\
| fields env, label, cluster, role, group, monitoring_state\
| lookup kafka_burrow_consumers_monitoring env, label, cluster, group OUTPUT group as collection_found | where isnull(collection_found) | fields - collection_found\
| outputlookup kafka_burrow_consumers_monitoring append=t key_field=_key

#   ___   ___ _____ ____       _    _     _____ ____ _____ ___ _   _  ____
#  / _ \ / _ \_   _| __ )     / \  | |   | ____|  _ \_   _|_ _| \ | |/ ___|
# | | | | | | || | |  _ \    / _ \ | |   |  _| | |_) || |  | ||  \| | |  _
# | |_| | |_| || | | |_) |  / ___ \| |___| |___|  _ < | |  | || |\  | |_| |
#  \___/ \___/ |_| |____/  /_/   \_\_____|_____|_| \_\|_| |___|_| \_|\____|
#

[Verify Kafka alerting maintenance status]
cron_schedule = */15 * * * *
description = This scheduled report verifies the default maintenance status, if no status is set, it will be disabled by default
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | makeresults\
| appendcols [ | inputlookup kafka_alerting_maintenance ]\
| eval maintenance_mode=if(isnull(maintenance_mode), "disabled", maintenance_mode), time_updated=if(isnull(time_updated), now(), time_updated)\
| eval maintenance_mode=if(isnotnull(maintenance_mode_end) AND maintenance_mode_end<now(), "disabled", maintenance_mode)\
| eval maintenance_mode=if(isnotnull(maintenance_mode_start) AND isnotnull(maintenance_mode_end) AND now()>=maintenance_mode_start AND maintenance_mode_end>now(), "enabled", maintenance_mode)\
| eval maintenance_mode_start=if(isnotnull(maintenance_mode_end) AND maintenance_mode_end<now(), "", maintenance_mode_start), maintenance_mode_end=if(isnotnull(maintenance_mode_end) AND maintenance_mode_end<now(), "", maintenance_mode_end)\
| eval time_updated=if(maintenance_mode="enabled" AND isnotnull(maintenance_mode_end) AND maintenance_mode_end<now(), now, time_updated)\
| eval time_updated=if(maintenance_mode="enabled" AND isnotnull(maintenance_mode_start) AND isnotnull(maintenance_mode_end) AND now()>=maintenance_mode_start AND maintenance_mode_end<now(), now, time_updated)\
| fields - time | table maintenance_mode, maintenance_mode_start, maintenance_mode_end, time_updated | outputlookup kafka_alerting_maintenance

# All alerts are disabled by default, administrators shall enable every alert that makes sense, and optionally add the alert action if connection to a ticketing system is relevant
# or any other action desired.

# OOTB alerting provides deep traditional alerting of the Kafka infrastructure components

# By default, alerts are due to throttle on a per component basis for the next 4 hours after it triggers, administrators should change this according to SLA in place.

#  _     ___ _____ _____   _____ _____ ____ _____
# | |   |_ _|  ___| ____| |_   _| ____/ ___|_   _|
# | |    | || |_  |  _|     | | |  _| \___ \ | |    _____
# | |___ | ||  _| | |___    | | | |___ ___) || |   |_____|
# |_____|___|_|   |_____|   |_| |_____|____/ |_|
#
#  ____ _____  _    _     _____   __  __ _____ _____ ____  ___ ____ ____
# / ___|_   _|/ \  | |   | ____| |  \/  | ____|_   _|  _ \|_ _/ ___/ ___|
# \___ \ | | / _ \ | |   |  _|   | |\/| |  _|   | | | |_) || | |   \___ \
#  ___) || |/ ___ \| |___| |___  | |  | | |___  | | |  _ < | | |___ ___) |
# |____/ |_/_/   \_\_____|_____| |_|  |_|_____| |_| |_| \_\___\____|____/
#

# Life tests alerts, called stale metrics, verify the metrics availability to deduce a potential life test failure of the component.
# These life tests may trigger if there is any issue in the metric land space (component cannot be reached, issue in Splunk) or if the component is really down/unreachable and has a major outage.

[Kafka monitoring - Zookeeper - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="zookeeper.avg_latency" OR metric_name="zookeeper.open_file_descriptor_count" by env, label, server span=1s\
| stats max(_time) as last_time by env, label, server | rename server as name | eval role="zookeeper"\
| append [ | inputlookup kafka_infra_inventory | where role="zookeeper"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_controller.ActiveControllerCount.Value" by env, label, jolokia_agent_url span=1s\
| stats max(_time) as last_time by env, label, jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_broker"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_broker"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Connect - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_connect.worker.connector-count" by env, label, jolokia_agent_url span=1s\
| stats max(_time) as last_time by env, label, jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_connect"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_connect"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Confluent schema-registry - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_schema-registry.master-slave-role.master-slave-role" by env, label, jolokia_agent_url span=1s\
| stats max(_time) as last_time by env, label, jolokia_agent_url | rename jolokia_agent_url as name | eval role="schema-registry"\
| append [ | inputlookup kafka_infra_inventory | where role="schema-registry"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Confluent ksql-server - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_ksql-server.messages-consumed-per-sec" OR metric_name="kafka_ksql-server.messages-produced-per-sec" by env, label, jolokia_agent_url span=1s\
| stats max(_time) as last_time by env, label, jolokia_agent_url | rename jolokia_agent_url as name | eval role="ksql-server"\
| append [ | inputlookup kafka_infra_inventory | where role="ksql-server"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Confluent kafka-rest - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_kafka-rest.jetty-metrics.connections-active" by env, label, jolokia_agent_url span=1s\
| stats max(_time) as last_time by env, label, jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_rest"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_rest"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Linkedin Kafka Monitor - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_kafka-monitor.produce-availability-avg" OR metric_name="kafka_kafka-monitor.consume-availability-avg" by env, label, jolokia_agent_url span=1s\
| stats max(_time) as last_time by env, label, jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_linkedin_monitor"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_linkedin_monitor"]\
| stats first(last_time) as last_time values(*) as "*" by env, label, name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, env, label, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

#  _     ___ _____ _____   _____ _____ ____ _____
# | |   |_ _|  ___| ____| |_   _| ____/ ___|_   _|
# | |    | || |_  |  _|     | | |  _| \___ \ | |    _____
# | |___ | ||  _| | |___    | | | |___ ___) || |   |_____|
# |_____|___|_|   |_____|   |_| |_____|____/ |_|
#
#  ____ _____  _    _     _____   __  __ _____ _____ ____  ___ ____ ____
# / ___|_   _|/ \  | |   | ____| |  \/  | ____|_   _|  _ \|_ _/ ___/ ___|
# \___ \ | | / _ \ | |   |  _|   | |\/| |  _|   | | | |_) || | |   \___ \
#  ___) || |/ ___ \| |___| |___  | |  | | |___  | | |  _ < | | |___ ___) |
# |____/ |_/_/   \_\_____|_____| |_|  |_|_____| |_| |_| \_\___\____|____/
#
#  _                        _   _                             _
# | |__  _   _    __ _  ___| |_(_)_   _____   _ __   ___   __| | ___  ___
# | '_ \| | | |  / _` |/ __| __| \ \ / / _ \ | '_ \ / _ \ / _` |/ _ \/ __|
# | |_) | |_| | | (_| | (__| |_| |\ V /  __/ | | | | (_) | (_| |  __/\__ \
# |_.__/ \__, |  \__,_|\___|\__|_| \_/ \___| |_| |_|\___/ \__,_|\___||___/
#        |___/
#                        _
#  _ __  _   _ _ __ ___ | |__   ___ _ __
# | '_ \| | | | '_ ` _ \| '_ \ / _ \ '__|
# | | | | |_| | | | | | | |_) |  __/ |
# |_| |_|\__,_|_| |_| |_|_.__/ \___|_|
#

[All Kafka components - active node numbers - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, role
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if the number of active nodes generating metrics is lower than the defined minimal number of nodes, or null. (components are down)\
The minimal number of nodes and monitoring state can be configured within the kv_kafka_infra_nodes_inventory kvstore collection.
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | savedsearch telegraf-kafka-zookeeper-servers | rename server as name | fields env, label, name, role, monitoring_state\
| append [ | savedsearch telegraf-kafka-kafka-brokers | rename jolokia_agent_url as name | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-connect-workers | rename jolokia_agent_url as name | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-schema-registry | rename jolokia_agent_url as name | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-ksql-server | rename jolokia_agent_url as name | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-rest | rename jolokia_agent_url as name | fields env, label, name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-monitor | rename jolokia_agent_url as name | fields env, label, name, role, monitoring_state ]\
| stats count(name) as current_nodes_number by env, label, role\
| append [ | inputlookup kafka_infra_nodes_inventory | fields env, label, role, minimal_nodes_number, monitoring_state ]\
| stats first(*) as "*" by env, label, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| eval current_nodes_number=if(isnotnull(current_nodes_number), current_nodes_number, 0)\
| eval state=if(current_nodes_number>=minimal_nodes_number, "normal", "severe")\
| fields env, label, role, current_nodes_number, minimal_nodes_number, monitoring_state, maintenance_mode, state\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

#  _  __      __ _           _               _
# | |/ /__ _ / _| | ____ _  | |__  _ __ ___ | | _____ _ __ ___
# | ' // _` | |_| |/ / _` | | '_ \| '__/ _ \| |/ / _ \ '__/ __|
# | . \ (_| |  _|   < (_| | | |_) | | | (_) |   <  __/ |  \__ \
# |_|\_\__,_|_| |_|\_\__,_| |_.__/|_|  \___/|_|\_\___|_|  |___/
#

[Kafka monitoring - Kafka Brokers - Failed producer or consumer was detected]
alert.digest_mode = 0
alert.suppress = 1
alert.suppress.fields = env, label, kafka_broker, metric_name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats avg(_value) as value where `telegraf_kafka_index` metric_name="kafka_topic.FailedProduceRequestsPerSec.OneMinuteRate" OR metric_name="kafka_topic.FailedFetchRequestsPerSec.OneMinuteRate" by metric_name, env, label, jolokia_agent_url\
| eval value=round(value, 2)\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.\w*"\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| fields jolokia_agent_url, kafka_broker, metric_name, value\
| lookup kafka_infra_inventory env, label, name as jolokia_agent_url OUTPUT monitoring_state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - ISR Shrinking detection]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, kafka_broker
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = The rate at which the ISR is shrinking. The ISRwill shrink if a broker is shutdown, either gracefullyor not.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_replica_manager.IsrShrinksPerSec.OneMinuteRate" by metric_name, env, label, jolokia_agent_url \
| eval value=round(value, 2)\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.Value"\
| fields env, label, jolokia_agent_url, kafka_broker, metric_name, value\
| lookup kafka_infra_inventory env, label, name as jolokia_agent_url OUTPUT monitoring_state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - Offline or Under-replicated partitions]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = env, label, kafka_broker, metric_name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Under-replicated partitions : This measurement, provided on each broker in a cluster, gives a count of the number of partitions for which the broker is the leader replica, where the follower replicas are not caught up. This single measurement provides insight into a number of problems with the Kafka cluster, from a broker being down to resource exhaustion.\
\
Offline partitions: Along with the under-replicated partitions count, the offline partitions count is a critical metric for monitoring. This measurement is only provided by the broker that is the controller for the cluster (all other brokers will report 0), and shows the number of partitions in the cluster that currently have no leader. Partitions without leaders can happen for two main reasons:• All brokers hosting replicas for this partition are down• No in-sync replica can take leadership due to message-count mismatches (with unclean leader election disabled)
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_replica_manager.UnderReplicatedPartitions.Value" OR metric_name="kafka_controller.OfflinePartitionsCount.Value" by metric_name, env, label, jolokia_agent_url \
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.Value"\
| fields env, label, jolokia_agent_url, kafka_broker, metric_name, value\
| lookup kafka_infra_inventory env, label, name as jolokia_agent_url OUTPUT monitoring_state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - Abnormal number of Active Controllers (2 minutes grace period)]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = env, label, kafka_broker
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Within a Kafka cluster, there should always be 1 Active Controller only. (value=1)\
This alert will trigger if more than 1 broker claims to be the active controller, with a grace period of 2 minutes.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_controller.ActiveControllerCount.Value" by env, label, metric_name, jolokia_agent_url span=1s\
| stats latest(value) as value, max(_time) as  _time by metric_name, env, label, jolokia_agent_url\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.\w*"\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| fields _time, env, label, jolokia_agent_url, kafka_broker, metric_name, value\
| lookup kafka_infra_inventory env, label, name as jolokia_agent_url OUTPUT monitoring_state\
| eval now=now(), epoch=strftime(_time, "%s"), delta=now-epoch\
| appendpipe [ stats sum(value) as value, max(delta) as delta ]\
| eval state=if(value>1 AND delta>120, "severe", "normal")\
| rename delta as "delta_second_last_value" | fields - epoch, now\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND monitoring_state="enabled" AND state="severe" AND NOT maintenance_mode="enabled"

#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | |_ ___  _ __ (_) ___ ___
# | ' // _` | |_| |/ / _` | | __/ _ \| '_ \| |/ __/ __|
# | . \ (_| |  _|   < (_| | | || (_) | |_) | | (__\__ \
# |_|\_\__,_|_| |_|\_\__,_|  \__\___/| .__/|_|\___|___/
#                                    |_|

[Kafka monitoring - Kafka Topics - Under-replicated partitions detected on topic]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = env, label, topic
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Detection of topics with under-replicated partitions
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name=kafka_partition.UnderReplicatedPartitions topic="kafka-monitor-topic" by env, label, topic, partition, jolokia_agent_url\
| where value>0\
| stats sum(value) as no_under_replicated_partitions, values(partition) as id_partitions, values(jolokia_agent_url) as kafka_brokers by env, label, topic\
| rex field=jolokia_agent_url "//(?<kafka_brokers>[^:]*)\:"\
| lookup kafka_topics_monitoring env, label, topic\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where no_under_replicated_partitions>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Topics - errors detected on a topic]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = env, label, topic
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Errors on Kafka topics
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats avg(_value) as value where `telegraf_kafka_index` metric_name="kafka_topic.BytesRejectedPerSec.OneMinuteRate" OR metric_name="kafka_topic.FailedFetchRequestsPerSec.OneMinuteRate" OR metric_name="kafka_topic.FailedProduceRequestsPerSec.OneMinuteRate" topic!="__*" topic!="_*" by env, label, jolokia_agent_url, metric_name, topic\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.\w*"\
| rex field=jolokia_agent_url "//(?<jolokia_agent_url>[^:]*)\:" | rename jolokia_agent_url as kafka_broker\
| lookup kafka_topics_monitoring env, label, topic\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#

[Kafka monitoring - Kafka Connect - tasks status monitoring]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, connector
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if the status of a Kafka Connect source or task connector has currently no active tasks.\
Which will determine if a connector is an operational state.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as task_state_id where `telegraf_kafka_index` metric_name="kafka_connect.connector-task.status" connector=* by env, label, connector, jolokia_agent_url, task span=1s\
| stats max(_time) as lasttime, values(jolokia_agent_url) as jolokia_agent_url, min(task_state_id) as task_state_id, values(task) as task by env, label, connector\
| eval task_state=case(task_state_id=0, "paused", task_state_id=1, "running", task_state_id=2, "unassigned", task_state_id=3, "failed", task_state_id=4, "destroyed")\
| append [ | inputlookup kafka_connect_tasks_monitoring ]\
| stats first(task_state) as task_state, values(jolokia_agent_url) as jolokia_agent_url, values(task) as task, max(lasttime) as lasttime, first(_key) as _key, first(role) as role, first(grace_period) as grace_period, first(monitoring_state) as monitoring_state by env, label, connector\
| outputlookup kafka_connect_tasks_monitoring append=f key_field=_key\
| appendpipe [ | stats dc(task) as number_tasks by env, label, connector ]\
| stats values(*) as "*" by env, label, connector\
| rename task as task_id | rex field=jolokia_agent_url "//(?<connect_worker>[^:]*)\:"\
| fields env, label, connector, connect_worker, monitoring_state, task_state, number_tasks, task_id, grace_period, lasttime\
| eval now=now(), delta_seconds=now-lasttime, now=strftime(now, "%d/%m/%Y %H:%M:%S"), lasttime=strftime(lasttime, "%d/%m/%Y %H:%M:%S")\
| eval state=case(number_tasks<1 AND delta_seconds>=grace_period AND task_state!="running", "severe",\
number_tasks<1 AND isnull(delta_seconds) AND task_state!="running", "severe",\
number_tasks>=1 AND delta_seconds<grace_period AND task_state="running", "normal")\
| rename now as "check_time"\
| fillnull value="severe" state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Connect - connector or task startup failure detected]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, connector
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if the status of a Kafka Connect worker fails to start a connector or its tasks.\
Which will determine if a connector is an operational state.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats max(_value) as value WHERE `telegraf_kafka_index` metric_name="kafka_connect.worker.task-startup-failure-total" OR metric_name="kafka_connect.worker.connector-startup-failure-total" by env, label, metric_name, jolokia_agent_url span=1s\
| eval {metric_name}=value | stats first(kafka_connect.*) as "*" by _time, env, label, jolokia_agent_url\
| stats max(_time) as _time, latest(worker.*) as "*", latest(worker.*) as "*" by env, label, jolokia_agent_url\
| lookup kafka_infra_inventory env, label, name as jolokia_agent_url OUTPUT monitoring_state\
| rex field=jolokia_agent_url "//(?<connect_worker>[^:]*)\:" | eval connector-startup-failure-total=round('connector-startup-failure-total', 0), task-startup-failure-total=round('task-startup-failure-total', 0)\
| fields _time, env, label, connect_worker, connector-startup-failure-total, task-startup-failure-total, monitoring_state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where ('connector-startup-failure-total'>0 OR 'task-startup-failure-total'>0) AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

#  ____
# | __ ) _   _ _ __ _ __ _____      __
# |  _ \| | | | '__| '__/ _ \ \ /\ / /
# | |_) | |_| | |  | | | (_) \ V  V /
# |____/ \__,_|_|  |_|  \___/ \_/\_/
#
#   ____
# / ___|___  _ __  ___ _   _ _ __ ___   ___ _ __ ___
# | |   / _ \| '_ \/ __| | | | '_ ` _ \ / _ \ '__/ __|
# | |__| (_) | | | \__ \ |_| | | | | | |  __/ |  \__ \
#  \____\___/|_| |_|___/\__,_|_| |_| |_|\___|_|  |___/
#
#                        _ _             _
#  _ __ ___   ___  _ __ (_) |_ ___  _ __(_)_ __   __ _
# | '_ ` _ \ / _ \| '_ \| | __/ _ \| '__| | '_ \ / _` |
# | | | | | | (_) | | | | | || (_) | |  | | | | | (_| |
# |_| |_| |_|\___/|_| |_|_|\__\___/|_|  |_|_| |_|\__, |
#                                                |___/

[Kafka monitoring - Burrow - group consumers state monitoring]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = env, label, cluster, group
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if the status of a group consumer monitored by Burrow is a non OK or unknown state.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as status_code where metric_name="burrow_group.status_code" `telegraf_kafka_index` group!="" env="*" label="*" cluster="*" group="*" by env, label, cluster, group span=1s\
| stats latest(status_code) as status_code, max(_time) as last_time by env, label, cluster, group\
| lookup burrow_status status_code OUTPUT status, description as status_description\
| append [ | inputlookup kafka_burrow_consumers_monitoring ]\
| stats first(last_time) as last_time values(*) as "*" by env, label, cluster, group\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S")\
| eval state=case(status_code!=1, "severe", status_code=1, "low"), state=if(delta_seconds>120, "severe", state), status=if(delta_seconds>120, "unknown", status), status_description=if(delta_seconds>120, "The delta in seconds between the last state received and now has exceeded 120 seconds", status_description)\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds)\
| rename now as "check_time"\
| fillnull value="severe" state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"\
| table env, label, cluster, last_time, check_time, delta_seconds, group, maintenance_mode, monitoring_state, state, status, status_code, status_description\
| fillnull value="unknown" status, status_code, status_description

#  ____  _____ ____   ___  ____ _____ ____
# |  _ \| ____|  _ \ / _ \|  _ \_   _/ ___|
# | |_) |  _| | |_) | | | | |_) || | \___ \
# |  _ <| |___|  __/| |_| |  _ < | |  ___) |
# |_| \_\_____|_|    \___/|_| \_\|_| |____/
#

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#

[Kafka monitoring - tasks status report]
description = This report shows the status of all Kafka Connect tasks reporting during the period of the search.
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
display.visualizations.show = 0
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as status WHERE `telegraf_kafka_index` metric_name="kafka_connect.connector-task.status" env=* label=* jolokia_agent_url=* by metric_name, env, label, jolokia_agent_url, connector, task span=1s\
| stats max(_time) as lastTime, latest(status) as integer_status, latest(jolokia_agent_url) as jolokia_agent_url by env, label, connector, task\
| eval status=case((integer_status == 0),"paused",(integer_status == 1),"running",(integer_status == 2),"unassigned",(integer_status == 3),"failed",(integer_status == 4),"destroyed")\
| sort limit=0 env, label, connector, task\
| stats list(jolokia_agent_url) as jolokia_agent_url, list(task) as task, list(integer_status) as integer_status, list(status) as status, max(lastTime) as lastTime by env, label, connector\
| join max=1 overwrite=1 type=inner usetime=0 connector env label\
    [| mcatalog values(metric_name) as metric_name where `telegraf_kafka_index` OR index="kafka_monitoring" metric_name="kafka_connect.source-task.source-record-poll-total" OR metric_name="kafka_connect.sink-task.sink-record-read-total" connector=* by env, label, jolokia_agent_url, connector\
    | eval role=case(match(metric_name,"sink-task"),"kafka_sink_task",match(metric_name,"source-task"),"kafka_source_task")\
    | fields env, label, connector, role]\
| fields env, label, jolokia_agent_url, connector, role, task, status, integer_status, lastTime\
| eval now=now(), delta=(now - lastTime), status=if((delta > 90),"time range out of scope, state undetermined",status)\
| fields - delta, now\
| eval lastTime=strftime(lastTime,"%d/%m/%Y %H:%M:%S")\
| eval integer_status=if(status="time range out of scope, state undetermined", 5, integer_status)\
| streamstats min(integer_status) as range by env, label, connector\
| rangemap field=range elevated=0-0 low=1-1 default=severe
