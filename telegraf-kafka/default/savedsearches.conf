# savedsearches.conf

#  _____           _
# |__  /___   ___ | | _____  ___ _ __   ___ _ __
#   / // _ \ / _ \| |/ / _ \/ _ \ '_ \ / _ \ '__|
#  / /| (_) | (_) |   <  __/  __/ |_) |  __/ |
# /____\___/ \___/|_|\_\___|\___| .__/ \___|_|
#                               |_|

# The following search will discover all zookeeper servers reporting to the telegraf metric indexes
[telegraf-kafka-zookeeper-servers]
search = | mcatalog values(server) as server where `telegraf_kafka_index` metric_name="zookeeper.avg_latency" OR metric_name="zookeeper.open_file_descriptor_count"\
| mvexpand server\
| eval role="zookeeper"\
| fields role, server

#  _  __      __ _           _               _
# | |/ /__ _ / _| | ____ _  | |__  _ __ ___ | | _____ _ __ ___
# | ' // _` | |_| |/ / _` | | '_ \| '__/ _ \| |/ / _ \ '__/ __|
# | . \ (_| |  _|   < (_| | | |_) | | | (_) |   <  __/ |  \__ \
# |_|\_\__,_|_| |_|\_\__,_| |_.__/|_|  \___/|_|\_\___|_|  |___/
#

[telegraf-kafka-kafka-brokers]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_controller.ActiveControllerCount.Value"\
| mvexpand jolokia_agent_url\
| eval role="kafka_broker"\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| fields role, jolokia_agent_url, kafka_broker

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#

[telegraf-kafka-kafka-connect-workers]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_connect.worker.connector-count"\
| mvexpand jolokia_agent_url\
| eval role="kafka_connect"\
| rex field=jolokia_agent_url "//(?<kafka_connect>[^:]*)\:"\
| fields role, jolokia_agent_url, kafka_connect

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#
#  _            _
# | |_ __ _ ___| | _____
# | __/ _` / __| |/ / __|
# | || (_| \__ \   <\__ \
#  \__\__,_|___/_|\_\___/
#
#   ______                              ______  _       _   __
#  / / ___|  ___  _   _ _ __ ___ ___   / / ___|(_)_ __ | | _\ \
# | |\___ \ / _ \| | | | '__/ __/ _ \ / /\___ \| | '_ \| |/ /| |
# | | ___) | (_) | |_| | | | (_|  __// /  ___) | | | | |   < | |
# | ||____/ \___/ \__,_|_|  \___\___/_/  |____/|_|_| |_|_|\_\| |
#  \_\                                                      /_/
#

[telegraf-kafka-kafka-connect-tasks]
search = | mcatalog values(jolokia_agent_url) as kafka_task_nodes values(metric_name) as metric_name where `telegraf_kafka_index` metric_name="kafka_connect.source-task.source-record-poll-total" OR metric_name="kafka_connect.sink-task.sink-record-read-total" connector=* by connector\
| eval role=case(match(metric_name, "sink-task"), "kafka_sink_task", match(metric_name, "source-task"), "kafka_source_task")\
| fields - metric_name\
| rename connector as kafka_task\
| nomv kafka_task_nodes | rex field=kafka_task_nodes mode=sed "s/ /|/g"\
| fields role, kafka_task, kafka_task_nodes

#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | |_ ___  _ __ (_) ___ ___
# | ' // _` | |_| |/ / _` | | __/ _ \| '_ \| |/ __/ __|
# | . \ (_| |  _|   < (_| | | || (_) | |_) | | (__\__ \
# |_|\_\__,_|_| |_|\_\__,_|  \__\___/| .__/|_|\___|___/
#                                    |_|

[telegraf-kafka-kafka-topics]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_topic.MessagesInPerSec.Count" OR metric_name="kafka_topic.BytesInPerSec.Count" topic!="__*" topic!="_*" by topic\
| eval role="kafka_topic"\
| rename topic as kafka_topic, jolokia_agent_url as kafka_topic_brokers\
| nomv kafka_topic_brokers | rex field=kafka_topic_brokers mode=sed "s/ /|/g"\
| fields role, kafka_topic, kafka_topic_brokers

#   ____             __ _                  _
#  / ___|___  _ __  / _| |_   _  ___ _ __ | |_
# | |   / _ \| '_ \| |_| | | | |/ _ \ '_ \| __|
# | |__| (_) | | | |  _| | |_| |  __/ | | | |_
#  \____\___/|_| |_|_| |_|\__,_|\___|_| |_|\__|
#
#  _  __      __ _           ____       _                                ____            _     _
# | |/ /__ _ / _| | ____ _  / ___|  ___| |__   ___ _ __ ___   __ _      |  _ \ ___  __ _(_)___| |_ _ __ _   _
# | ' // _` | |_| |/ / _` | \___ \ / __| '_ \ / _ \ '_ ` _ \ / _` |_____| |_) / _ \/ _` | / __| __| '__| | | |
# | . \ (_| |  _|   < (_| |  ___) | (__| | | |  __/ | | | | | (_| |_____|  _ <  __/ (_| | \__ \ |_| |  | |_| |
# |_|\_\__,_|_| |_|\_\__,_| |____/ \___|_| |_|\___|_| |_| |_|\__,_|     |_| \_\___|\__, |_|___/\__|_|   \__, |
#                                                                                  |___/                |___/

[telegraf-kafka-schema-registry]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_schema-registry.master-slave-role.master-slave-role"\
| mvexpand jolokia_agent_url\
| eval role="schema-registry"\
| rex field=jolokia_agent_url "//(?<kafka_schema_registry>[^:]*)\:"\
| fields role, jolokia_agent_url, kafka_schema_registry

#   ____             __ _                  _
#  / ___|___  _ __  / _| |_   _  ___ _ __ | |_
# | |   / _ \| '_ \| |_| | | | |/ _ \ '_ \| __|
# | |__| (_) | | | |  _| | |_| |  __/ | | | |_
#  \____\___/|_| |_|_| |_|\__,_|\___|_| |_|\__|
#
#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | | _____  __ _| |      ___  ___ _ ____   _____ _ __
# | ' // _` | |_| |/ / _` | | |/ / __|/ _` | |_____/ __|/ _ \ '__\ \ / / _ \ '__|
# | . \ (_| |  _|   < (_| | |   <\__ \ (_| | |_____\__ \  __/ |   \ V /  __/ |
# |_|\_\__,_|_| |_|\_\__,_| |_|\_\___/\__, |_|     |___/\___|_|    \_/ \___|_|
#                                        |_|

[telegraf-kafka-ksql-server]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_ksql-server.messages-consumed-per-sec" OR metric_name="kafka_ksql-server.messages-produced-per-sec"\
| mvexpand jolokia_agent_url\
| eval role="ksql-server"\
| rex field=jolokia_agent_url "//(?<kafka_ksql_server>[^:]*)\:"\
| fields role, jolokia_agent_url, kafka_ksql_server

#   ____             __ _                  _
#  / ___|___  _ __  / _| |_   _  ___ _ __ | |_
# | |   / _ \| '_ \| |_| | | | |/ _ \ '_ \| __|
# | |__| (_) | | | |  _| | |_| |  __/ | | | |_
#  \____\___/|_| |_|_| |_|\__,_|\___|_| |_|\__|
#
#  _          __ _                             _
# | | ____ _ / _| | ____ _       _ __ ___  ___| |_
# | |/ / _` | |_| |/ / _` |_____| '__/ _ \/ __| __|
# |   < (_| |  _|   < (_| |_____| | |  __/\__ \ |_
# |_|\_\__,_|_| |_|\_\__,_|     |_|  \___||___/\__|
#

[telegraf-kafka-kafka-rest]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_kafka-rest.jetty-metrics.connections-active"\
| mvexpand jolokia_agent_url\
| eval role="kafka_rest"\
| rex field=jolokia_agent_url "//(?<kafka_rest>[^:]*)\:"\
| fields role, jolokia_agent_url, kafka_rest

#  _     _       _            _ _
# | |   (_)_ __ | | _____  __| (_)_ __
# | |   | | '_ \| |/ / _ \/ _` | | '_ \
# | |___| | | | |   <  __/ (_| | | | | |
# |_____|_|_| |_|_|\_\___|\__,_|_|_| |_|
#
#  _  __      __ _                                     _ _
# | |/ /__ _ / _| | ____ _       _ __ ___   ___  _ __ (_) |_ ___  _ __
# | ' // _` | |_| |/ / _` |_____| '_ ` _ \ / _ \| '_ \| | __/ _ \| '__|
# | . \ (_| |  _|   < (_| |_____| | | | | | (_) | | | | | || (_) | |
# |_|\_\__,_|_| |_|\_\__,_|     |_| |_| |_|\___/|_| |_|_|\__\___/|_|
#

[telegraf-kafka-kafka-monitor]
search = | mcatalog values(jolokia_agent_url) as jolokia_agent_url where `telegraf_kafka_index` metric_name="kafka_kafka-monitor.produce-availability-avg" OR metric_name="kafka_kafka-monitor.consume-availability-avg"\
| mvexpand jolokia_agent_url\
| eval role="kafka_linkedin_monitor"\
| fields role, jolokia_agent_url

#     _    _     _
#    / \  | |   | |
#   / _ \ | |   | |
#  / ___ \| |___| |___
# /_/   \_\_____|_____|
#
#   ____ ___  __  __ ____   ___  _   _ _____ _   _ _____ ____
#  / ___/ _ \|  \/  |  _ \ / _ \| \ | | ____| \ | |_   _/ ___|
# | |  | | | | |\/| | |_) | | | |  \| |  _| |  \| | | | \___ \
# | |__| |_| | |  | |  __/| |_| | |\  | |___| |\  | | |  ___) |
#  \____\___/|_|  |_|_|    \___/|_| \_|_____|_| \_| |_| |____/
#
#  ___ _   ___     _______ _   _ _____ ___  ______   __
# |_ _| \ | \ \   / / ____| \ | |_   _/ _ \|  _ \ \ / /
#  | ||  \| |\ \ / /|  _| |  \| | | || | | | |_) \ V /
#  | || |\  | \ V / | |___| |\  | | || |_| |  _ < | |
# |___|_| \_|  \_/  |_____|_| \_| |_| \___/|_| \_\|_|
#

[Update Kafka Infrastructure components inventory]
cron_schedule = 0 1 * * *
description = This scheduled report will update the Kafka infrastructure collection
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | savedsearch telegraf-kafka-zookeeper-servers | eval monitoring_state="enabled" | rename server as name | fields name, role, monitoring_state\
| append [ | savedsearch telegraf-kafka-kafka-brokers | rename jolokia_agent_url as name | eval monitoring_state="enabled" | fields name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-connect-workers | rename jolokia_agent_url as name | eval monitoring_state="enabled" | fields name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-schema-registry | rename jolokia_agent_url as name | eval monitoring_state="enabled" | fields name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-ksql-server | rename jolokia_agent_url as name | eval monitoring_state="enabled" | fields name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-rest | rename jolokia_agent_url as name | eval monitoring_state="enabled" | fields name, role, monitoring_state ]\
| append [ | savedsearch telegraf-kafka-kafka-monitor | rename jolokia_agent_url as name | eval monitoring_state="enabled" | fields name, role, monitoring_state ]\
| eval grace_period="300"\
| search NOT [ | inputlookup kafka_infra_inventory | fields name ]\
| outputlookup kafka_infra_inventory append=t key_field=_key

#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | |_ ___  _ __ (_) ___ ___
# | ' // _` | |_| |/ / _` | | __/ _ \| '_ \| |/ __/ __|
# | . \ (_| |  _|   < (_| | | || (_) | |_) | | (__\__ \
# |_|\_\__,_|_| |_|\_\__,_|  \__\___/| .__/|_|\___|___/
#                                    |_|
#  ___                      _
# |_ _|_ ____   _____ _ __ | |_ ___  _ __ _   _
#  | || '_ \ \ / / _ \ '_ \| __/ _ \| '__| | | |
#  | || | | \ V /  __/ | | | || (_) | |  | |_| |
# |___|_| |_|\_/ \___|_| |_|\__\___/|_|   \__, |
#                                         |___/
#

[Update Kafka topics inventory]
cron_schedule = 0 1 * * *
description = This scheduled report will update the Kafka infrastructure collection
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search = | mcatalog values(topic) as topic where `telegraf_kafka_index` metric_name="kafka_topic.MessagesInPerSec.Count" OR metric_name="kafka_topic.BytesInPerSec.Count" topic!="__*" topic!="_*"\
| mvexpand topic\
| eval grace_period="300", monitoring_state="enabled"\
| search NOT [ | inputlookup kafka_topics_monitoring | fields topic ]\
| outputlookup kafka_topics_monitoring append=t key_field=_key

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#
#  _            _
# | |_ __ _ ___| | _____
# | __/ _` / __| |/ / __|
# | || (_| \__ \   <\__ \
#  \__\__,_|___/_|\_\___/
#
#  ___                      _
# |_ _|_ ____   _____ _ __ | |_ ___  _ __ _   _
#  | || '_ \ \ / / _ \ '_ \| __/ _ \| '__| | | |
#  | || | | \ V /  __/ | | | || (_) | |  | |_| |
# |___|_| |_|\_/ \___|_| |_|\__\___/|_|   \__, |
#                                         |___/
#

[Update Kafka Connect tasks inventory]
cron_schedule = 0 1 * * *
description = This scheduled report will update the Kafka Connect task inventory collection
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | mcatalog values(connector) as connector where `telegraf_kafka_index` metric_name="kafka_connect.source-task.source-record-poll-total" OR metric_name="kafka_connect.sink-task.sink-record-read-total" connector=* by metric_name\
| mvexpand connector\
| eval role=case(match(metric_name, "sink-task"), "kafka_sink_task", match(metric_name, "source-task"), "kafka_source_task")\
| eval grace_period="300", monitoring_state="enabled"\
| fields connector, role, grace_period, monitoring_state\
| search NOT [ | inputlookup kafka_connect_tasks_monitoring | fields connector ]\
| outputlookup kafka_connect_tasks_monitoring append=t key_field=_key

#   ___   ___ _____ ____       _    _     _____ ____ _____ ___ _   _  ____
#  / _ \ / _ \_   _| __ )     / \  | |   | ____|  _ \_   _|_ _| \ | |/ ___|
# | | | | | | || | |  _ \    / _ \ | |   |  _| | |_) || |  | ||  \| | |  _
# | |_| | |_| || | | |_) |  / ___ \| |___| |___|  _ < | |  | || |\  | |_| |
#  \___/ \___/ |_| |____/  /_/   \_\_____|_____|_| \_\|_| |___|_| \_|\____|
#

[Verify Kafka alerting maintenance status]
cron_schedule = 0 1 * * *
description = This scheduled report verifies the default maintenance status, if no status is set, it will be disabled by default
dispatch.earliest_time = -4h
dispatch.latest_time = now
enableSched = 1
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
schedule_window = 5
run_on_startup = true
search  = | makeresults\
| appendcols [ | inputlookup kafka_alerting_maintenance ]\
| eval maintenance_mode=if(isnull(maintenance_mode), "disabled", maintenance_mode)\
| fields - _time | outputlookup kafka_alerting_maintenance

# All alerts are disabled by default, administrators shall enable every alert that makes sense, and optionally add the alert action if connection to a ticketing system is relevant
# or any other action desired.

# OOTB alerting provides deep traditional alerting of the Kafka infrastructure components

# By default, alerts are due to throttle on a per component basis for the next 4 hours after it triggers, administrators should change this according to SLA in place.

#  _     ___ _____ _____   _____ _____ ____ _____
# | |   |_ _|  ___| ____| |_   _| ____/ ___|_   _|
# | |    | || |_  |  _|     | | |  _| \___ \ | |    _____
# | |___ | ||  _| | |___    | | | |___ ___) || |   |_____|
# |_____|___|_|   |_____|   |_| |_____|____/ |_|
#
#  ____ _____  _    _     _____   __  __ _____ _____ ____  ___ ____ ____
# / ___|_   _|/ \  | |   | ____| |  \/  | ____|_   _|  _ \|_ _/ ___/ ___|
# \___ \ | | / _ \ | |   |  _|   | |\/| |  _|   | | | |_) || | |   \___ \
#  ___) || |/ ___ \| |___| |___  | |  | | |___  | | |  _ < | | |___ ___) |
# |____/ |_/_/   \_\_____|_____| |_|  |_|_____| |_| |_| \_\___\____|____/
#

# Life tests alerts, called stale metrics, verify the metrics availability to deduce a potential life test failure of the component.
# These life tests may trigger if there is any issue in the metric land space (component cannot be reached, issue in Splunk) or if the component is really down/unreachable and has a major outage.

[Kafka monitoring - Zookeeper - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="zookeeper.avg_latency" OR metric_name="zookeeper.open_file_descriptor_count" by server span=1s\
| stats max(_time) as last_time by server | rename server as name | eval role="zookeeper"\
| append [ | inputlookup kafka_infra_inventory | where role="zookeeper"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_controller.ActiveControllerCount.Value" by jolokia_agent_url span=1s\
| stats max(_time) as last_time by jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_broker"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_broker"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Connect - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_connect.worker.connector-count" by jolokia_agent_url span=1s\
| stats max(_time) as last_time by jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_connect"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_connect"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Confluent schema-registry - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_schema-registry.master-slave-role.master-slave-role" by jolokia_agent_url span=1s\
| stats max(_time) as last_time by jolokia_agent_url | rename jolokia_agent_url as name | eval role="schema-registry"\
| append [ | inputlookup kafka_infra_inventory | where role="schema-registry"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Confluent ksql-server - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_ksql-server.messages-consumed-per-sec" OR metric_name="kafka_ksql-server.messages-produced-per-sec" by jolokia_agent_url span=1s\
| stats max(_time) as last_time by jolokia_agent_url | rename jolokia_agent_url as name | eval role="ksql-server"\
| append [ | inputlookup kafka_infra_inventory | where role="ksql-server"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Confluent kafka-rest - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_kafka-rest.jetty-metrics.connections-active" by jolokia_agent_url span=1s\
| stats max(_time) as last_time by jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_rest"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_rest"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Linkedin Kafka Monitor - stale metrics life test]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if no metrics were available for the component during the time range of the search, according to the configure grace period in seconds.\
\
Monitoring of the component must be enabled in the KVstore collection "kafka_infra_inventory".
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_kafka-monitor.produce-availability-avg" OR metric_name="kafka_kafka-monitor.consume-availability-avg" by jolokia_agent_url span=1s\
| stats max(_time) as last_time by jolokia_agent_url | rename jolokia_agent_url as name | eval role="kafka_linkedin_monitor"\
| append [ | inputlookup kafka_infra_inventory | where role="kafka_linkedin_monitor"]\
| stats first(last_time) as last_time values(*) as "*" by name\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S"), state=case(delta_seconds>=grace_period, "severe", isnull(delta_seconds), "severe", delta_seconds<grace_period, "normal")\
| eval last_time=if(isnull(last_time), "out of time range scope", last_time), delta_seconds=if(isnull(delta_seconds), "out of time range scope", delta_seconds) \
| rename now as "life_test_time"\
| fields life_test_time, name, last_time, delta_seconds, grace_period, state, monitoring_state, role\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

#  _  __      __ _           _               _
# | |/ /__ _ / _| | ____ _  | |__  _ __ ___ | | _____ _ __ ___
# | ' // _` | |_| |/ / _` | | '_ \| '__/ _ \| |/ / _ \ '__/ __|
# | . \ (_| |  _|   < (_| | | |_) | | | (_) |   <  __/ |  \__ \
# |_|\_\__,_|_| |_|\_\__,_| |_.__/|_|  \___/|_|\_\___|_|  |___/
#

[Kafka monitoring - Kafka Brokers - Failed producer or consumer was detected]
alert.digest_mode = 0
alert.suppress = 1
alert.suppress.fields = kafka_broker, metric_name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats avg(_value) as value where `telegraf_kafka_index` metric_name="kafka_topic.FailedProduceRequestsPerSec.OneMinuteRate" OR metric_name="kafka_topic.FailedFetchRequestsPerSec.OneMinuteRate" by metric_name, jolokia_agent_url\
| eval value=round(value, 2)\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.\w*"\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| fields jolokia_agent_url, kafka_broker, metric_name, value\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - ISR Shrinking detection]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = kafka_broker
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = The rate at which the ISR is shrinking. The ISRwill shrink if a broker is shutdown, either gracefullyor not.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_replica_manager.IsrShrinksPerSec.OneMinuteRate" by metric_name, jolokia_agent_url \
| eval value=round(value, 2)\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.Value"\
| fields jolokia_agent_url, kafka_broker, metric_name, value\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - Offline or Under-replicated partitions]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = kafka_broker, metric_name
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Under-replicated partitions : This measurement, provided on each broker in a cluster, gives a count of the number of partitions for which the broker is the leader replica, where the follower replicas are not caught up. This single measurement provides insight into a number of problems with the Kafka cluster, from a broker being down to resource exhaustion.\
\
Offline partitions: Along with the under-replicated partitions count, the offline partitions count is a critical metric for monitoring. This measurement is only provided by the broker that is the controller for the cluster (all other brokers will report 0), and shows the number of partitions in the cluster that currently have no leader. Partitions without leaders can happen for two main reasons:• All brokers hosting replicas for this partition are down• No in-sync replica can take leadership due to message-count mismatches (with unclean leader election disabled)
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_replica_manager.UnderReplicatedPartitions.Value" OR metric_name="kafka_controller.OfflinePartitionsCount.Value" by metric_name, jolokia_agent_url \
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.Value"\
| fields jolokia_agent_url, kafka_broker, metric_name, value\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Brokers - Abnormal number of Active Controllers (2 minutes grace period)]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = kafka_broker
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Within a Kafka cluster, there should always be 1 Active Controller only. (value=1)\
This alert will trigger if more than 1 broker claims to be the active controller, with a grace period of 2 minutes.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name="kafka_controller.ActiveControllerCount.Value" by metric_name, jolokia_agent_url span=1s\
| stats latest(value) as value, max(_time) as  _time by metric_name, jolokia_agent_url\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.\w*"\
| rex field=jolokia_agent_url "//(?<kafka_broker>[^:]*)\:"\
| fields _time, jolokia_agent_url, kafka_broker, metric_name, value\
| eval now=now(), epoch=strftime(_time, "%s"), delta=now-epoch\
| appendpipe [ stats sum(value) as value, max(delta) as delta ]\
| eval state=if(value>1 AND delta>120, "severe", "normal")\
| rename delta as "delta_second_last_value" | fields - epoch, now\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND state="severe" AND NOT maintenance_mode="enabled"

#  _  __      __ _           _              _
# | |/ /__ _ / _| | ____ _  | |_ ___  _ __ (_) ___ ___
# | ' // _` | |_| |/ / _` | | __/ _ \| '_ \| |/ __/ __|
# | . \ (_| |  _|   < (_| | | || (_) | |_) | | (__\__ \
# |_|\_\__,_|_| |_|\_\__,_|  \__\___/| .__/|_|\___|___/
#                                    |_|

[Kafka monitoring - Kafka Topics - Under-replicated partitions detected on topic]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = topic
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Detection of topics with under-replicated partitions
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as value where `telegraf_kafka_index` metric_name=kafka_partition.UnderReplicatedPartitions topic="kafka-monitor-topic" by topic, partition, jolokia_agent_url\
| where value>0\
| stats sum(value) as no_under_replicated_partitions, values(partition) as id_partitions, values(jolokia_agent_url) as kafka_brokers by topic\
| rex field=jolokia_agent_url "//(?<kafka_brokers>[^:]*)\:"\
| lookup kafka_topics_monitoring topic\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where no_under_replicated_partitions>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Topics - errors detected on a topic]
alert.digest_mode = 0
alert.severity = 5
alert.suppress = 1
alert.suppress.fields = topic
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = Errors on Kafka topics
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats avg(_value) as value where `telegraf_kafka_index` metric_name="kafka_topic.BytesRejectedPerSec.OneMinuteRate" OR metric_name="kafka_topic.FailedFetchRequestsPerSec.OneMinuteRate" OR metric_name="kafka_topic.FailedProduceRequestsPerSec.OneMinuteRate" topic!="__*" topic!="_*" by jolokia_agent_url, metric_name, topic\
| rex field=metric_name "kafka_\w*\.(?<metric_name>\w*)\.\w*"\
| rex field=jolokia_agent_url "//(?<jolokia_agent_url>[^:]*)\:" | rename jolokia_agent_url as kafka_broker\
| lookup kafka_topics_monitoring topic\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where value>0 AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#

[Kafka monitoring - Kafka Connect - tasks status monitoring]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = connector
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if the status of a Kafka Connect source or task connector has currently no active tasks.\
Which will determine if a connector is an operational state.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as task_state_id where `telegraf_kafka_index` metric_name="kafka_connect.connector-task.status" connector=* by connector, jolokia_agent_url, task span=1s\
| stats max(_time) as last_time, values(jolokia_agent_url) as jolokia_agent_url, min(task_state_id) as task_state_id, values(task) as task by connector\
| eval task_state=case(task_state_id=0, "paused", task_state_id=1, "running", task_state_id=2, "unassigned", task_state_id=3, "failed", task_state_id=4, "destroyed")\
| append [ | inputlookup kafka_connect_tasks_monitoring ]\
| stats values(jolokia_agent_url) as jolokia_agent_url, values(task) as task, values(*) as "*" by connector\
| appendpipe [ | stats dc(task) as number_tasks by connector ]\
| stats values(*) as "*" by connector\
| rename task as task_id | rex field=jolokia_agent_url "//(?<connect_worker>[^:]*)\:"\
| fields connector, connect_worker, monitoring_state, task_state, number_tasks, task_id, grace_period, last_time\
| eval now=now(), delta_seconds=now-last_time, now=strftime(now, "%d/%m/%Y %H:%M:%S"), last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S")\
| eval state=case(number_tasks<1 AND delta_seconds>=grace_period AND task_state!="running", "severe", \
number_tasks<1 AND isnull(delta_seconds) AND task_state!="running", "severe",\
number_tasks>=1 AND delta_seconds<grace_period AND task_state="running", "normal")\
| rename now as "check_time"\
| fillnull value="severe" state\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where state="severe" AND monitoring_state="enabled" AND NOT maintenance_mode="enabled"

[Kafka monitoring - Kafka Connect - connector or task startup failure detected]
alert.digest_mode = 0
alert.severity = 4
alert.suppress = 1
alert.suppress.fields = connector
alert.suppress.period = 4h
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = This alert will trigger if the status of a Kafka Connect worker fails to start a connector or its tasks.\
Which will determine if a connector is an operational state.
dispatch.earliest_time = -5m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
disabled = true
enableSched = 1
quantity = 0
relation = greater than
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats max(_value) as value WHERE `telegraf_kafka_index` metric_name="kafka_connect.worker.task-startup-failure-total" OR metric_name="kafka_connect.worker.connector-startup-failure-total" by metric_name, jolokia_agent_url span=1s\
| eval {metric_name}=value | stats first(kafka_connect.*) as "*" by _time, jolokia_agent_url\
| stats max(_time) as _time, latest(worker.*) as "*", latest(worker.*) as "*" by jolokia_agent_url\
| rex field=jolokia_agent_url "//(?<connect_worker>[^:]*)\:" | eval connector-startup-failure-total=round('connector-startup-failure-total', 0), task-startup-failure-total=round('task-startup-failure-total', 0)\
| fields _time, connect_worker, connector-startup-failure-total, task-startup-failure-total\
| appendcols [ | inputlookup kafka_alerting_maintenance ] | filldown maintenance_mode\
| where ('connector-startup-failure-total'>0 OR 'task-startup-failure-total'>0) AND NOT maintenance_mode="enabled"

#  ____  _____ ____   ___  ____ _____ ____
# |  _ \| ____|  _ \ / _ \|  _ \_   _/ ___|
# | |_) |  _| | |_) | | | | |_) || | \___ \
# |  _ <| |___|  __/| |_| |  _ < | |  ___) |
# |_| \_\_____|_|    \___/|_| \_\|_| |____/
#

#  _  __      __ _            ____                            _
# | |/ /__ _ / _| | ____ _   / ___|___  _ __  _ __   ___  ___| |_
# | ' // _` | |_| |/ / _` | | |   / _ \| '_ \| '_ \ / _ \/ __| __|
# | . \ (_| |  _|   < (_| | | |__| (_) | | | | | | |  __/ (__| |_
# |_|\_\__,_|_| |_|\_\__,_|  \____\___/|_| |_|_| |_|\___|\___|\__|
#

[Kafka monitoring - tasks status report]
description = This report shows the status of all Kafka Connect tasks reporting during the period of the search.
dispatch.earliest_time = -15m
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.charting.chart = line
display.visualizations.show = 0
request.ui_dispatch_app = telegraf-kafka
request.ui_dispatch_view = search
search = | mstats latest(_value) as task_state_id where `telegraf_kafka_index` metric_name="kafka_connect.connector-task.status" connector=* by connector, jolokia_agent_url, task span=1s\
| stats max(_time) as last_time, values(jolokia_agent_url) as jolokia_agent_url, min(task_state_id) as task_state_id, values(task) as task by connector\
| eval task_state=case(task_state_id=0, "paused", task_state_id=1, "running", task_state_id=2, "unassigned", task_state_id=3, "failed", task_state_id=4, "destroyed")\
| stats values(jolokia_agent_url) as jolokia_agent_url, values(task) as task, values(*) as "*" by connector\
| appendpipe [ | stats dc(task) as number_tasks by connector ]\
| stats values(*) as "*" by connector\
| rename task as task_id | rex field=jolokia_agent_url "//(?<connect_worker>[^:]*)\:" | eval last_time=strftime(last_time, "%d/%m/%Y %H:%M:%S")\
| join connector [ | mcatalog values(connector) as connector where `telegraf_kafka_index` metric_name="kafka_connect.source-task.source-record-poll-total" OR metric_name="kafka_connect.sink-task.sink-record-read-total" connector=* by metric_name\
| mvexpand connector\
| eval connector_type=case(match(metric_name, "sink-task"), "kafka_sink_task", match(metric_name, "source-task"), "kafka_source_task")\
| fields connector, connector_type ]\
| fields connector, connector_type, connect_worker, task_state, number_tasks, task_id, last_time
